\chapter{Fundamentals}
\label{chp:fundamentals}
Firstly, this chapter outlines the concept of hybrid vehicles and how they work. Secondly, the cooperative game and specifically all required mathematical definitions are explained. Then six different game-theoretical solution approaches are presented.

\section{Hybrid vehicles}
This section explains the concept of hybrid cars and the distinct types which exist. It also describes how they operate under various driving conditions in order to achieve maximum efficiency.

A hybrid vehicle is a vehicle which utilizes more than one source of power, an engine and an electric motor. Energy is stored in both of them and also in the battery. The engine can use either gasoline or diesel as fuel. The goal of hybrid vehicles is to save fuel by combining the power of an internal combustion engine and the power of the electric motor. This is achieved by reusing the surplus power from the engine, which is often lost in conventional vehicles. In hybrids it is instead stored in the battery. By combining the ability of the electric motor to provide high torque in the small revolution speed range and the ability of the engine to produce high torque in the middle to high revolution speed range, hybrid vehicles achieve the required driving behaviour at a lower power cost. Hybrids can benefit from these opposing characteristics of the engine and the motor.

\subsection{Classification}
Hybrid vehicles can be classified into three distinct types - series, parallel and series-parallel. In serial hybrid vehicles only a single resource of power can be used at a time. The electric motor transmits torque to the wheels when there is enough battery power. Only the electric motor is connected to the wheels and it receives power from either the generator and the engine or from the battery. When the battery needs to be recharged, power is taken from the engine, which acts as a generator. In contrast, in parallel hybrid vehicles the wheels are driven by both the engine and the electric motor; hence, the name, because both power sources are able to run in parallel. There is a mechanical connection both from the engine and from the motor to the wheels. The engine is thought to be the main power supplier and the motor is used for boosting. If the motor is recharging the battery, it is impossible for it to also drive the vehicle at the same time. The third mixed type series-parallel benefits from the advantages of both designs by combining them. In this hybrid type it is possible that the engine drives the wheels or that the wheels are completely driven by the electric motor. The Toyota Prius is designed as a series-parallel hybrid vehicle.

\subsection{Driving behaviour}
A typical driving cycle begins by starting up. In the beginning it is efficient to use the motor for the low speed range up to the middle speed range and the engine can remain shut down. While maintaining a constant speed during cruising, power is distributed between the motor and engine so that both of them provide torque. In acceleration mode power is taken also from the battery, while both the engine and motor drive the vehicle again. During deceleration, the power from braking is recovered instead of lost and used to recharge the battery. The motor acts as a generator to convert the energy. This process is called regenerative braking. If the state of the charge of the battery falls below a certain percentage, it needs to be recharged by the engine which acts as a generator.

\section{Vehicle configuration of Toyota Prius}
This section gives an overview of the main components which every conventional car nowadays, not only hybrid cars, possess. Furthermore, it describes the special hybrid components while specifically adhering to one particular model of a hybrid car, namely the Toyota Prius, which was the first mass-produced hybrid car in 1997. The vehicle, whose parameters are used throughout this thesis for the Simulink vehicle model and for the simulation, is the Toyota Prius second generation, manufactured from 2003 to 2009.

\subsection{Internal Combustion Engine}
The internal combustion engine of the Toyota Prius is an Atkinson cycle engine. It is a 1.5 litres engine with maximum power of 57 kW or 76 hp at 5000 rpm. The maximum torque is 115 Nm at 4200 rpm. The Atkinson cycle is to be found mainly in hybrid-electric vehicles. Compared to a conventional Otto-cycle engine, the Atkinson cycle engine does not let as much air inside. The valve remains open longer and thus air can also escape. Consequently, the engine has a higher expansion ratio than compression ratio. A higher expansion ratio helps energy to be transformed from heat into mechanical energy, thus making the engine more effective. The goal is to acquire all available power of the engine by maintaining pressure balance so that the pressure after the power stroke is the same as the pressure of the atmosphere. This leads to reduced power in comparison with an Otto-cycle engine. However, additional power can be supplemented by the electric motor when necessary. Therefore, the Atkinson cycle was originally designed to provide more efficiency, but this happens at the cost of decreased power density. 

\subsection{Electric Motor}
The electric motor, which Toyota uses in its hybrid vehicles is a synchronous A/C motor because these motors can provide relatively large torque also in the high revolution per minute range. In the specific case of this motor, the torque at the maximum revolution speed of 6000 rpm is 70 Nm. The maximum torque of the motor is 400 Nm at 0 rpm and maximum power is 50 kW or 67 hp at 1200 rpm. In total the engine and the motor can generate power of 82 kW or 110 hp together.

A synchronous electric AC motor runs with Alternating Current (AC) as opposed to DC motors running with Direct Current. A typical AC motor has an inside rotor generating a magnetic field and an outside stator which creates another magnetic field. The rotor magnetic field in AC motor can be produced in different ways, for example, by permanent magnets such as in the Toyota Prius permanent magnet synchronous motor (PMSM). Permanent magnets produce a constant magnetic field. In synchronous motors the shaft is rotating with the same frequency as the supplying current. The permanent magnets on the rotor rotate in line with the stator magnetic field; hence, producing synchronized rotation. Such permanent magnet synchronous motors have to be started with power which is with variable frequency.

\subsection{Battery}
The battery is a 201.6V Nickel-metal hydride containing 28 modules, which can produce 1310 kWh in total. Each module consists of six 1.2V cells which are connected in series to generate in total 7.2V 6.5Ah. The weight of the whole battery pack is 53.3 kg. It consists of two battery packs, a high voltage (traction) and a low voltage. The low voltage battery pack is crucial when the vehicle starts because it provides initial power and the engine can remain shut down. The ultimate aim of the battery is to keep its SOC between 40-80\%. The advantage of Nickel metal hydride batteries over other types of batteries is that they have long lives. However, a significant disadvantage is their poor performance in cold temperatures. 

\subsection{Power Split Device}
Toyota patented the Hybrid Synergy Drive (HSD) which is a hybrid drive technology not only used in the Toyota Prius, but also in other models like Toyota Yaris and other car makers like Lexus and Nissan. The most crucial part is the gear set, called Power Split Device (PSD). It is a Continuously Variable Transmission (CVT) but it has a fixed gear ratio. Its main function is the combination of the power of the engine, the electric motor and the generator which all rotate with different speeds. The PSD is in itself a planetary (epicyclic) gear train such as the one shown in Figure \ref{fig:planGear}. It consists of four parts. In the middle there is a sun gear (yellow) and planet gears (blue) are revolving around the sun gear. The carrier is green and the annular gear is pink. The carrier is the part which connects the centres of the planet and the sun gears so that the planet gear can rotate around the sun gear. These three components are inside the annular gear which is a fixed outer circle. In fact, the Power Split Device is similar to a differential device. Therefore, the next subsection explains the function of a differential, which is to be found in every car.

\subsection{Differential}
After the power split device has fulfilled its purpose to transmit the torque to the wheels, a differential is required to cope with the difference in rotation speeds of the left and right wheels during turns. The primary function of a differential in vehicles is to allow the outer wheel to rotate faster than the inner wheel while the vehicle is turning left or right. A differential consists of three shafts, where the first is the input drive shaft and the other two are the outputs to the two wheels. These shafts possess the characteristic that the angular velocity of one of them is the average of the angular velocities of the other two. A further attribute of the angular velocities is that the mean velocity of both wheels is the same as the velocity of the input drive shaft. Therefore, if the velocity of one wheel grows, this is balanced by reducing the velocity of the other wheel.

\begin{figure}[h]
\centering
\includegraphics[scale=0.15]{figures/planetaryGear}
\caption{Planetary (epicyclic) gear train \citep{planetaryGear}}
\label{fig:planGear}
\end{figure}

\section{Game definition}
This section handles the formal definition of the game and the applied game-theoretical solution approaches. Firstly, the generic game definition is given. Additional definitions for each of the solution approaches are defined in the corresponding subsections of each solution.

According to \citet{holler2006einfuhrung} a game $G = (N,S,u)$ is defined by:
\begin{itemize}
\item
set of players $N = \{1,2\}$, in this case two players, where player 1 is the Engine and player 2 is the Motor.
\item
strategy space $S$, which is the set of all possible strategy combinations $s=(s_1,s_2)$ for each player, where $s \in S$. The strategy space contains two sets with all strategy combinations of that player.
\item
utility function $u = (u_1,u_2)$, where $u_i(s)$ for $i=1,2$ gives the utility (or also called payoff) for that player when the strategy combination $s$ is played.
\item
utility space (payoff space) which is the set of all possible utility combinations:
$P = \{u(s)|s \in S\} = \{(u_1(s),u_2(s),  \forall s \in S\}$
\end{itemize} 

Let us denote the number of pure strategies of each player with $m$ and $n$. Therefore, these constitute a bimatrix game, meaning that the payoffs of the game can be represented in two matrices of size $m \times n$. Let the strategy spaces constitute $s_1 = \{s_1^1,...,s_1^m\}$ and $s_2 = \{s_2^1,...,s_1^n\}$. Furthermore, let the payoff matrices $A$ and $B$ denote the payoffs for the first player, the engine, and the second player, the motor respectively, where $A = (a_{ij}: i \in \{1,...,m\}, j \in \{ 1,...,n\})$ and $B = (b_{ij}: i \in \{1,...,m\}, j \in \{ 1,...,n\})$.  Their contents are shown in Table \ref{tab:payoffEngine} and Table \ref{tab:payoffMotor}. It should be noted that $u_1 = a, \; u_2 = b$ and $a$ and $b$ notations have been introduced for simplicity. Sometimes player 1 is called the row player and player 2 is called the column player, since their strategies vary along the rows or along the columns of the matrices. The game is a non-zero sum game, since the sum of the two payoff matrices is not 0, $A + B \neq 0$.

{\renewcommand{\arraystretch}{1.5}
\begin{table}[h]
\centering 
\begin{tabular}{ |c|c|c|c|c|c|c|c| } 
\hline
      & $\mathbf{s_2^1}$ & $\mathbf{s_1^2}$ & $\mathbf{s_1^3}$ & $\mathbf{s_1^4}$ & $\mathbf{s_1^5}$ & $\mathbf{s_1^6}$ & $\mathbf{s_1^7}$ \\ \hline 
 $\mathbf{s_1^1}$ & $a_{1,1}$ & $a_{1,2}$ & $a_{1,3}$ & $a_{1,4}$ & $a_{1,5}$ & $a_{1,6}$ & $a_{1,7}$  \\ \hline
 $\mathbf{s_1^2}$ & $a_{2,1}$ & $a_{2,2}$ & $a_{2,3}$ & $a_{2,4}$ & $a_{2,5}$ & $a_{2,6}$ & $a_{2,7}$  \\ \hline
 $\mathbf{s_1^3}$ & $a_{3,1}$ & $a_{3,2}$ & $a_{3,3}$ & $a_{3,4}$ & $a_{3,5}$ & $a_{3,6}$ & $a_{3,7}$  \\ \hline
 $\mathbf{s_1^4}$ & $a_{4,1}$ & $a_{4,2}$ & $a_{4,3}$ & $a_{4,4}$ & $a_{4,5}$ & $a_{4,6}$ & $a_{4,7}$  \\ \hline
 $\mathbf{s_1^5}$ & $a_{5,1}$ & $a_{5,2}$ & $a_{5,3}$ & $a_{5,4}$ & $a_{5,5}$ & $a_{5,6}$ & $a_{5,7}$  \\ \hline
 $\mathbf{s_1^6}$ & $a_{6,1}$ & $a_{6,2}$ & $a_{6,3}$ & $a_{6,4}$ & $a_{6,5}$ & $a_{6,6}$ & $a_{6,7}$  \\ \hline
 $\mathbf{s_1^7}$ & $a_{7,1}$ & $a_{7,2}$ & $a_{7,3}$ & $a_{7,4}$ & $a_{7,5}$ & $a_{7,6}$ & $a_{7,7}$  \\ \hline
\end{tabular}
\caption{Engine payoff matrix}
\label{tab:payoffEngine}
\end{table}

\begin{table}[h]
\centering 
\begin{tabular}{ |c|c|c|c|c|c|c|c| } 
\hline
      & $\mathbf{s_2^1}$ & $\mathbf{s_1^2}$ & $\mathbf{s_1^3}$ & $\mathbf{s_1^4}$ & $\mathbf{s_1^5}$ & $\mathbf{s_1^6}$ & $\mathbf{s_1^7}$ \\ \hline
 $\mathbf{s_1^1}$ & $b_{1,1}$ & $b_{1,2}$ & $b_{1,3}$ & $b_{1,4}$ & $b_{1,5}$ & $b_{1,6}$ & $b_{1,7}$  \\ \hline
 $\mathbf{s_1^2}$ & $b_{2,1}$ & $b_{2,2}$ & $b_{2,3}$ & $b_{2,4}$ & $b_{2,5}$ & $b_{2,6}$ & $b_{2,7}$  \\ \hline
 $\mathbf{s_1^3}$ & $b_{3,1}$ & $b_{3,2}$ & $b_{3,3}$ & $b_{3,4}$ & $b_{3,5}$ & $b_{3,6}$ & $b_{3,7}$  \\ \hline
 $\mathbf{s_1^4}$ & $b_{4,1}$ & $b_{4,2}$ & $b_{4,3}$ & $b_{4,4}$ & $b_{4,5}$ & $b_{4,6}$ & $b_{4,7}$  \\ \hline
 $\mathbf{s_1^5}$ & $b_{5,1}$ & $b_{5,2}$ & $b_{5,3}$ & $b_{5,4}$ & $b_{5,5}$ & $b_{5,6}$ & $b_{5,7}$  \\ \hline
 $\mathbf{s_1^6}$ & $b_{6,1}$ & $b_{6,2}$ & $b_{6,3}$ & $b_{6,4}$ & $b_{6,5}$ & $b_{6,6}$ & $b_{6,7}$  \\ \hline
 $\mathbf{s_1^7}$ & $b_{7,1}$ & $b_{7,2}$ & $b_{7,3}$ & $b_{7,4}$ & $b_{7,5}$ & $b_{7,6}$ & $b_{7,7}$  \\ \hline

\end{tabular}
\caption{Motor payoff matrix}
\label{tab:payoffMotor}
\end{table}

As opposed to a non-cooperative game, in cooperative games the players are allowed to make binding agreements among themselves in order to achieve a better payoff, that is, they can form coalitions. We distinguish between the grand coalition of all players $N$ or $\{1,2\}$, where they all cooperate, and the individual coalitions $\{i\}, \forall i \in N$ which are $\{1\}$ and $\{2\}$. There is also the empty coalition, where neither cooperates, but this coalition is irrelevant to our purposes. Each coalition has a value associated with it. The grand coalition forms its value as a sum of the payoffs of the engine and motor multiplied element-wise by a matrix with weights. The weights are distributed according to the torque deviation which the engine and motor produce. The torque deviation is defined as the difference between the required and the actual torque at the current time step. When the deviation is 0, the payoffs are weighted by 0.99, when it is between 0-10\% of the required torque it is weighted by 0.991, when between 10-20\% weight is 0.992 and so on up to 1.0 (the full sum of engine and motor torque).


The goal of the game is to save fuel and to maintain low gas emissions while achieving the required torque at any moment in time. Therefore, the payoffs are penalties as opposed to benefits and they have to be minimized. All of the solutions have been defined by taking into account that this is a minimization problem. Most of the solutions applied in the literature work with maximizing payoffs, but for the purpose of this thesis their definitions and implementations have been modified to minimize the two payoff functions instead. 


There exist two types of cooperative games - with transferable and with non-transferable utility. In transferable utility (TU) games the payoff of one player can be transferred to another player without any loss. In contrast, in non-transferable utility (NTU) games the payoffs of each player cannot be redistributed among the other players. In this thesis the payoffs of the engine and the motor are not interchangeable, since decreasing the payoff of one player does not mean increasing the payoff of the other player at the same time. Therefore, their payoff functions are thought to be independent from each other.

The payoff functions are constructed in the following way. The engine payoff is:
\begin{equation}
\label{eq:payoffEngine}
\begin{split}
a_{ij} = w_1 \times fuelConsumptionRate + w_2 \times | requiredTorque - actualTorque | + \\
w_3 \times HCemissions + w_4 \times COemissions + w_5 \times NOXemissions + \\
w_6 \times fuelConsumed
\end{split}
\end{equation}

Where the fuel consumption rate is in grams per second (\textit{gps}), the difference between required and actual torque is in Newton meters (\textit{Nm}), the gas emissions are all in \textit{gps} and the consumed fuel from the beginning of the simulation up to this time step is in litres. The motor payoff is:
\begin{equation}
\label{eq:payoffMotor}
\begin{split}
b_{ij} = w_2 \times | requiredTorque - actualTorque | + w_7 \times powerConsumed\\
w_8 \times SOCdeviation
\end{split}
\end{equation}
Where the consumed power is in \textit{kW} from the beginning of the simulation and SOC deviation is the difference between the target SOC of 70\% and the current SOC of the battery.

To summarize, the game defined is a two-player cooperative bimatrix non-zero-sum game with non-transferable utility.

\section{Game-theoretical solution approaches}
This thesis examines a variety of solution approaches for cooperative games which are later applied and simulated as described. The following section describes the theoretical and mathematical definitions of the six solution concepts. These are Pareto Optimality, Nash Equilibrium, Nash bargaining solution, Kalai-Smorodinsky bargaining solution, the Core and the Shapley value.

\subsection{Pareto Efficiency and Pareto Optimality}
In the literature two terms are often used to refer to the same concept - Pareto Efficiency and Pareto Optimality. However, they are used with distinct meanings throughout this thesis. Pareto Efficiency denotes an allocation of resources such that no player can improve their outcome without impairing another player. In the strategy space of the game there can exist more than one Pareto efficient outcome. Therefore, we define a Pareto optimal outcome, or Pareto Optimality, as the single best outcome from the set of all Pareto efficient outcomes. The criteria for determining the best outcome is as follows. All Pareto efficient points are compared by their torque deviation and the point with the least torque deviation is taken as the Pareto optimal point. Torque deviation is defined as the absolute difference between the required and the actual torque at this stage of the game. If more than one outcomes have the same torque deviation the outcome with the smallest fuel consumption rate is taken as a second criterion. Similarly, if more than one outcome have the same fuel consumption rate the one with the smallest power consumed by the motor is taken. This is the third and last criterion.

\subsection{Nash Bargaining solution}
The Nash Bargaining solution or shortly the Nash solution was defined by \citet{nash1950bargaining}. It considers the game as a bargaining game where each player requests some portion of the existing good, in this case torque. A bargaining game $G$ is defined by specifying a conflict point $c = (c_1,c_2)$ in addition to the payoff space $P$, comprising of the two payoff vectors as defined above $u = (u_1,u_2)$. The pair is denoted as $(P,c)$ as in \citet{holler2006einfuhrung}. The conflict point is the point where both players do not cooperate with each other. There exists a common misinterpretation because the word "conflict" point itself implies a point where both players face a disagreement and hence their payoffs are the worst. A Nash Equilibrium does not present such a worst case and therefore the term conflict point may seem misleading, but for the sake of consistency in the literature, the term will be kept as it is. Since the conflict point in the literature is often taken to be the Nash Equilibrium of the corresponding non-cooperative game, the next subsection deals with an algorithm to find a Nash Equilibrium.

Taking these into account, a Nash Bargaining solution is the vector $u^*$ from the set $P$:
\begin{equation}
\label{eq:nashProduct}
NP^* = max(c_1 - u_1^* )(c_2 - u_2^*)
\end{equation}

so that $u^* = (u_1^*,u_2^*) \in P$ and $u_i^* < c_i$ for $i = 1,2$, meaning that the Nash solution point $u^*$ payoff is less than the conflict point payoff. The main idea of the Nash solution expressed graphically as in Figure \ref{fig:nashSol} is to maximize the product of the differences between the conflict point and the Nash solution point coordinates in 2D.

\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{figures/nashSolution}
\caption{Maximized Nash Product}
\label{fig:nashSol}
\end{figure}

The Nash solution is characterized by four axioms as defined in \citet{holler2006einfuhrung}. 

The first axiom is called Invariance with Respect to Affine Transformations of Utility. Given a bargaining game $(P,c)$ and two random real numbers $a_i > 0$ and $b_i$, where $i = 1,2$ for both players, it is true that $f_i(P',c') = a_i f_i(P,c) + b_i$. This holds if $(P',c')$ is a game resulting from a linear transformation which preserves the order of all points $u$ and $c$ from $P$ so that $y_i = a_i x_i + b_i$ and $c_i' = a_i c_i + b_i$, where $y \in P'$ and $c' \in P'$. In other words such a linear transformation of the game space does not affect the solution of the bargaining game.

The second axiom is Symmetry. If $(P,c)$ is a symmetric bargaining game then $f_1(P,c) = f_2(P,c)$. A game is symmetric if $c_1 = c_2$ and if $(u_1, u_2)$ and $(u_2, u_1)$ are both in the payoff space $P$. This results in a conflict point lying on the 45\textdegree  line from the origin of the coordinate system. $P$ is symmetric with regard to this line. This axiom tells that if the payoffs of the two players can be interchanged and the game does not change as a consequence of that, then its solution should also not distinguish between the two players.

The third axiom is Independence of Irrelevant Alternatives. It states that $f(P,c) = f(Q,c)$ if two games $(P,c)$ and $(Q,c)$ have the same conflict point $c$, $P \subseteq Q$ and $f(Q,c) \in P$. Therefore, only the conflict point is relevant, because if the payoff space of the game is extended to a superset or it is shrunk to a subset, then the solution itself does not change.

The last axiom is the Pareto Optimality. For a bargaining game $(P,c)$ there is no $x \neq f(P,c)$ in P such that $x_1 \leq f_1(P,c)$ and $x_2 \leq f_2(P,c)$, which is an example of group rationality.

\subsection{Nash Equilibrium}
This subsection firstly describes formally the concept of Nash Equilibrium and then presents the Lemke-Howson algorithm for finding one Nash Equilibrium.

The notion of an equilibrium was firstly presented by \citet{nash1950equilibrium} in his one-page paper where he defined an equilibrium as a self-countering n-tuple of strategies. An n-tuple is said to counter another n-tuple if the strategy of each player in the first n-tuple gives him the largest possible payoff against the n-1 strategies of the other players in the second n-tuple \citep{nash1950equilibrium}. 

Let $s^*$ be a strategy combination where each player chooses an optimal strategy $s_i^*$ assuming that all other players have also chosen their optimal strategies. A strategy of a player $i$ is called optimal when $i$ cannot achieve a better payoff given the current decisions (strategies) of the other players denoted as $-i$. Then, a Nash Equilibrium is formally defined as a strategy combination such that \citep{holler2006einfuhrung}:
\begin{equation}
u_i(s_i^*, s_{-i}^*) \leq u_i(s_i,s_{-i}^*), \; \forall i, \forall s_i \in S_i
\end{equation}
Therefore, in an Nash Equilibrium state no player has the incentive to deviate from his strategy assuming that all other players also keep their strategies unaltered. Each player has to guess which strategy his opponent will play and based on that to choose his own best strategy. Nevertheless, there can be several best responses and this means several Nash Equilibria. \citet{nash1950equilibrium} classifies the equilibria into three types - solutions, strong solutions and sub-solutions. It is possible that a non-cooperative game does not have a solution. However, if it has, then the solution must be unique which is what a strong solution is. A sub-solution is not necessarily unique. \citet{holler2006einfuhrung} present a theorem for the existence of a Nash Equilibrium in a game $G(N,S,u)$ with the following characteristics. If the strategy space is compact and convex $S_i \subset R^m, \forall i \in N$ and it is true that $u_i(s)$ is continuous and bounded in $s \in S$ and quasi-concave in $s_i$, then there exists a Nash Equilibrium. However, a lot of functions do not fulfil these prerequisites for continuity and quasi-concavity and hence have no Nash Equilibrium in pure strategies. In this case the game can be extended to mixed strategies by assigning probabilities to each pure strategy or also called randomization. By randomizing the strategies of matrix games the strategy space $S_i$ can be transformed to a convex and compact space and the payoff $u_i(s)$ to quasi-concave.  

\subsection{Lemke-Howson algorithm}
\label{subsec:lemkehowson}
One of the most popular algorithms for finding a Nash Equilibrium for bimatrix non-zero-sum games is the Lemke-Howson algorithm \citep{lemke1964equilibrium}. The Matlab implementation developed by \citet{lemkeHowson2014Matlab} was utilized to find one Nash Equilibrium in mixed strategies. This function contains a parameter, which affects the final result of the algorithm. Changing the parameter yields different Nash equilibria as output. This parameter $k$ is the initial pivot, a number between 1 and $m+n$, where $m$ and $n$ are the number of strategies of player 1 and player 2 respectively. The general idea of the the algorithm is that it works on two graphs containing nodes and edges, one graph per player. It starts at the (0,0) point. It selects a $k$, the pivot, or the label of the graph, containing the strategy to be dropped first when traversing the graph. From there a path to the end is followed in order to find a Nash Equilibrium. 

There a number of reasons for the different Nash Equilibrium solutions that the algorithm produces. According to \citet{lemke1964equilibrium} there exist an odd number of Nash Equilibria in any non-degenerate game. A non-degenerate game is a game where no mixed strategy with a support of size $k$ has more than $k$ pure strategies \citep{nisan2007algorithmic}. Moreover, a support of a mixed strategy is defined as the set of pure strategies with positive probabilities. Since there is an odd number of Nash Equilibria, there must be at least one Equilibrium, which proves that the algorithm will always find one solution in mixed strategies. However, which of all Nash Equilibria is found depends on which strategy label is dropped first. The initial pivot label which the algorithm drops can belong to either of the two players and be any of their $m$ or $n$ strategies.

As discussed in \citet{shapley1974note} the Lemke-Howson algorithm possesses a significant weakness, namely that it is neither guaranteed that the algorithm will find all possible solutions, nor that it will tell if there are any unfound solutions.

The fundamentals of the Lemke-Howson algorithm are described next. Let us assume a scenario of a 2-player bimatrix game as the one used throughout this thesis, where the players $1$ and $2$ each have $n$ and $m$ number of pure strategies and their payoffs are in the matrices $A = (a_{ij}: i \in \{1,...,m\}, j \in \{ m+1,...,m+n\})$ and $B = (b_{ij}: i \in \{1,...,m\}, j \in \{m+1,...,m+n\})$ respectively. The mixed strategies are the vectors $s=(s_1,s_2...,s_m)$ and $t=(t_{m+1},t_{m+2},...,t_{m+n})$ where $S = \{s \geq 0; \sum_{i=1}^{m}s_i = 1\}$ and $T = \{t \geq 0; \sum_{j=m+1}^{m+n}t_i = 1\}$ are the sets for the mixed strategies spaces. Then, the payoff for player 1 is $\sum_{i=1}^{m}\sum_{j=m+1}^{m+n} a_{ij} s_i t_j$ and the payoff for player 2 is $\sum_{i=1}^{m} \sum_{j=m+1}^{m+n} b_{ij} s_i t_j$. An equilibrium is a pair of strategies $(s^*,t^*)$ satisfying:
\begin{equation}
\sum_{i=1}^{m} \sum_{j=m+1}^{m+n} a_{ij}s_i^*t_j^* = \max_{s \in S} \sum_{i=1}^{m} \sum_{j=m+1}^{m+n} a_{ij}s_i t_j^*
\end{equation}
\begin{equation}
\sum_{i=1}^{m} \sum_{j=m+1}^{m+n} b_{ij}s_i^*t_j^* = \max_{t \in T} \sum_{i=1}^{m} \sum_{j=m+1}^{m+n} b_{ij}s_i^* t_j
\end{equation}


If we also define the sets:
\begin{equation}
\tilde{S} =  S \cup \{ s \geq 0: \sum_{i=1}^{m} s_i \leq 1 \text{ and } \prod_{i=1}^{m} s_i = 0 \}
\end{equation}

\begin{equation}
\tilde{T} = T \cup \{t \geq 0: \sum_{j=m+1}^{m+n} t_i \leq 1 \text{ and } \prod_{j=m+1}^{m+n} t_i = 0 \}
\end{equation}
this allows us to define closed convex polyhedral regions $S^i$ and $S^j$ which together form $S^k \in \tilde{S}$:
\begin{equation}
S^i = \{ s \in \tilde{S}: s_i = 0 \} \text{ for } i \in \{1,...,m\}
\end{equation}


\begin{equation}
S^j = \Big\{ s \in S: \sum_{i=1}^{m} b_{ij} s_i = \max_{l \in \{m+1,...,m+n\}} \sum_{i=1}^{m} b_{il} s_i \Big\} \text{ for } j \in \{m+1,...,m+n\}
\end{equation}


$S^i$ contains all $\tilde{S}-S$ and $S^j$ contains the mixed strategies for player 1 and the pure strategy $j$ of player 2 which is his best outcome. $S^i$ and $S^j$ both make $S^k$ and cover the whole set $\tilde{S}$. The same can be applied to define the regions $T^k \in \tilde{T}$:
\begin{equation} 
T^i = \Big\{ t \in T: \sum_{j=m+1}^{m+n} a_{ij} t_j = \max_{l \in \{1,...,m\}} \sum_{j=m+1}^{m+n} a_{lj} t_j \Big\} \text{ for } i \in \{1,...,m\} 
\end{equation}

\begin{equation}
T^j = \{ t \in \tilde{T}: t_j = 0 \} \text{ for } j \in \{m+1,...,m+n\} 
\end{equation}


The Lemke-Howson algorithm represents the strategies of both players in two graphs with nodes and edges. The already mentioned definitions are required in order to define a labelling for the graphs. A labelling of a node consists of all of the labels of all surrounding regions of this node. Let the nonempty label of $s \in \tilde{S}$ be $L'(s) = \{ k: s \in S^k \}$ and similarly the nonempty label of $t \in \tilde{T}$ be $L''(t) = \{ k: t \in T^k \}$ and the label of the node pair with pure strategies $(s,t) \in \tilde{S} \times \tilde{T}$ be $L(s,t) = L'(s) \cup L''(t)$. A node pair $(s,t)$ is completely labelled whenever $L(s,t) = K$, meaning that it contains the labels for all regions $k \in K$. A node pair is almost completely labelled if $L(s,t) = K - \{k\}$ for some $k \in K$. 

Then, as in \citet{shapley1974note} a node pair $(s,t) \in S \times T$ is an equilibrium point of (A,B) if and only if $(s,t)$ is completely labelled. Let the two graphs be $G' \in \tilde{S}$ and $G'' \in \tilde{T}$. Two nodes are adjacent if they are on the two ends of the same edge which means that their labels differ in exactly one element. The set of k almost completely labelled nodes in the graphs and their edges are the disjoint paths of the graph and cycles. The equilibria of the game are always located at the end of these paths. Also, the starting node, by default (0,0) is called an artificial equilibria and it is also located at the end of a path.

The algorithm works by starting at $(s,t) = (0,0) \in G' \times G'' $. Then a label $k$, which is to be dropped from $(s,t)$, is chosen (initial pivot). This $k$ can belong to either $n$ or $m$. Let this node be $(s,t)$ and its new label (after dropping $k$) be $l$. Then, if $l=k$ a Nash Equilibrium is reached. If $l\neq k$, then the algorithm continues by dropping another label and continuing until a completely labelled node has been reached, which is an equilibrium point.

\subsection{Kalai-Smorodinsky Bargaining Solution}
The Nash Bargaining solution has the significant disadvantage that it is not monotonic. The third of the four axioms defined above Independence of Irrelevant Alternatives was criticized as in \citet{kalai1975other}. Therefore, \citet{kalai1975other} propose another unique bargaining solution called the Kalai-Smorodinsky solution. They replace the third axiom with another axiom for Individual Monotonicity, which the Nash solution does not conform to. 

The axiom states that if for two bargaining games $(P,c)$ and $(R,c)$ such that $P \subset R$ the equation $m_i(P) = m_i(R)$ holds for player $i$, then for player $j \neq i$ it is true that $f_j(R,c) \geq f_j(P,c)$.

$m_i(P,c)$ and $m_i(R,c)$ denote the minimum payoffs for players $i = 1,2$. They are defined as $m_i(P) = min(u_i | (u_1,u_2) \in P$. The point $m(P) = (m_1(P),m_2(P))$ is called the ideal point of the game, because that is where both players achieve minimum payoffs; hence, the ideal outcome of the game. However, often this point is not feasible. As in the Nash solution, the conflict point is also crucial in the Kalai-Smorodinsky solution. A further term is required and this is the Utility Boundary of the utility space $P$ of a game:


Consequently, the Kalai-Smorodinsky solution is defined as follows:
\begin{equation}
\label{eq:kalaismorodinsky}
\frac{c_2 - u_2}{c_1 - u_1} = \frac{c_2 - m_2}{c_1 - m_1}
\end{equation}

so that
\begin{equation}
u_i \leq v_i, \frac{c_2 - v_2}{c_1 - v_1} = \frac{c_2 - m_2}{c_1 - m_1} 
\end{equation}

where $(v_1,v_2) \in P$. The pair $(u_1,u_2)$ is the Kalai-Smorodinsky solution. As \citet{kalai1975other} point out, this solution is graphically represented as the intersection point of the line $L(c,m)$ and the utility (payoff) boundary $H(P)$ as shown in Figure \ref{fig:ksSol}. $L(c,m)$ is the line connecting the conflict point $c$ and the ideal point $m$. The utility boundary $H(P)$ or also called the Pareto frontier is defined as the set of all Pareto efficient points. For all random payoffs of one player the boundary gives the minimal possible payoff of the other player. If the Pareto frontier only contains one Pareto efficient point then the Kalai-Smorodinsky solution is the ideal point itself $u = m(P)$.

\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{figures/kalaiSmorodinskySolution}
\caption{Kalai-Smorodinsky Solution}
\label{fig:ksSol}
\end{figure}

\subsection{Core}
\label{subsec:core}
As opposed to the previous four solution approaches, which treated the game as individually cooperative, the next two approaches, the Core and the Shapley value regard the game as coalitional. The difference is that the previous approaches were applicable to 2-player individually cooperative games only, whereas the Core and the Shapley value can additionally be extended to coalitional n-player games. However, this thesis only deals with 2-player games and therefore does not need this extension. Moreover, there is a crucial distinction between the Core and the Shapley value because the Core produces a set of points as a solution, while the Shapley value is always only one single point. For this reason the Core is similar to the Pareto efficiency concept because both can contain more than one point. A single point from this set needs to be chosen and the criteria for choosing a single solution from the Core is the same as in the case of Pareto efficiency - torque deviation, fuel consumption rate and power consumed by the motor are taken into account.

To define the core of a game, a new term called imputation is introduced. An imputation is such an allocation of resources that is both individually rational and group rational (or Pareto efficient). For transferable utility (TU) games individual rationality means that each player in the coalition receives at most the payoff that they would receive on their own expressed as $u_i \leq v(\{i\})$. Group rationality, which is equivalent to efficiency and in our case also to Pareto efficiency, means that the sum of the payoffs of all players in the grand coalition is the value of the game, $\sum_{i=1}^{N} u_i = v(N)$. For non-transferable utility (NTU) games such as ours a payoff vector $u$ is an imputation when there is no vector $u'$ which strictly dominates it. This is expressed by $u' \in V(N)$ such that $u'_i < u_i, \forall i\in N$. According to \citet{holler2006einfuhrung} a vector $u'$ is said to dominate another vector $u$ with regard to the coalition $K$ if $u'_i \leq u_i, \forall i \in K$ and for at least one $i \in K$ the inequality $u'_i < u_i$ holds when $u' \in V(K), u \in V(K)$.

After describing the notion of imputation, the core $C$ of a game $G$ is the defined as the set of all non-dominated imputations:
\begin{equation}
\label{eq:core}
C(G) = \{u \;|\; v(K) - \sum u_i \leq 0, \; \forall i \in K, \; \forall K \in N \}
\end{equation}

If an imputation $x$ is in the core $x \in C(G)$ then for all coalitions $K \in N$ there is no other coalition $K$ for which another imputation $y$ dominates $x$ denoted as \textit{y dom x via K} \citep{holler2006einfuhrung}. Therefore, no coalition can make its participants better by substituting $x$ with $y$; hence, $x$ is thought to be coalitionally rational. There are two different possibilities when this can be true. There is either no coalition at all which can realize $y$, or $y$ is worse than $x$ meaning that it is not true that $y_i < x_i$ for at least one $i \in K$ and $y_i \leq x_i$ for all $i \in K$. 

Since all imputations in the core are not dominated by any other imputation, the core is internally stable. The core of a game can be empty or can contain many imputations. This comes from the fact that the relation \textit{dom} is not transitive; hence, if it is true that an imputation $x$ dominates $y$ and $y$ dominates $z$, this does not imply that $x$ dominates $z$.

\subsection{Shapley Value}
\label{subsec:shapleyfund}
The Shapley value of a game with transferable utility according to \citet{holler2006einfuhrung} is defined as:
\begin{equation}
\label{eq:shapley}
\Phi_i(v) = \sum_{i \in K, K \subset N} \frac{(k-1)!(n-k)!}{n!} [ v(K) - v(K - \{i\})],
\end{equation}

\begin{equation}
\sum \Phi_i(v) = v(N), \; \Phi(v) = (\Phi_i(v))
\end{equation}
$k$ denotes the number of players in coalition $K$ and $n$ is the total number of players. $v(K)$ is the value of coalition $K$, whereas $v(K - \{i\})$ is the value of coalition $K$ without the player $i$. The sum of the Shapley values of all players must equal the total value of the game, which is also the value of the grand coalition $N$.

The Shapley value was introduced by \citet{shapley1952value} where it is described that the game must be represented by its characteristic function $v: 2^N	\rightarrow \mathbb{R}$. Therefore, to apply the Shapley value in our game which is defined only in its strategic form, the game has to be transformed into its coalitional form in order to get the characteristic function. The procedure is as follows. For each of the three relevant coalitions $\{1\}$, $\{2\}$, $\{1,2\}$ a value needs to be assigned. $v(N)$ or $v(1,2)$ is easy to find, because it is the minimum sum of the two payoff matrices $A$ and $B$. The values of each individual coalition $v(1)$ and $v(2)$ can be found by taking the Saddle point of the corresponding payoff matrix. A Saddle point of a two-player matrix game is both a column maximum and a row minimum. There can be more than one Saddle points in a matrix and they all have the same value. However, if no Saddle point exists in pure strategies, the game can be extended to mixed strategies in order to find a combination of pure strategies which give the value (the Saddle point) of the game. The exact implementation details are explained in \ref{subsec:shapleyimpl}.

In addition, the Shapley value is the single point which satisfies the following three axioms. The first axiom is Group Rationality or Efficiency, which is equivalent to Pareto efficiency. This axiom was already described in the subsection of Nash bargaining solution. The second axiom is Symmetry and it states that if the players change their order then the values of the players change accordingly. Therefore, the number, or the $i$, of the player does not have an influence on the value which that player receives. The third axiom is based on the assumption $\Phi_i(v+w) = \Phi_i(v) + \Phi_i(w)$ where $v+w$ is the combination of two games $v$ and $w$.

The general idea of the Shapley value is about permutations of the players and especially which player arrives first, meaning which player is able to make the decision first. The order of the players is irrelevant and all of the various orders have the same probability. Since there are $n!$ permutations of the players, the probability of each of them is $\frac{1}{n!}$ as shown in Equation \ref{eq:shapley}. Additionally, the probability of player $i$ being at the $k$-th place is $\frac{(k-1)!(n-k)!}{n!}$.
On the one hand, a player who has an influence on the value of the coalition is called a crucial or pivot player. A player $i$ is a pivot player whenever $K$ is a winning coalition and without him the coalition $K-\{i\}$ is a losing coalition. On the other hand, a player is called a dummy player when a coalition $K$ has the same value regardless whether $i$ is participating in it or not, $[v(K) - v(K-\{i\})]=0$.